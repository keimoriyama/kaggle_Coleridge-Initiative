{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vDl44wadxGkB"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNj5UnmVaSvt",
    "outputId": "6ec1dce9-00c9-4976-dd8f-52744b11fabe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "train-dataset-coleridge.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "Archive:  train-dataset-coleridge.zip\n",
      "replace bio_labeled_dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "if 'COLAB_GPU' in set(os.environ.keys()):\n",
    "  !mkdir -p ~/.kaggle\n",
    "  !cp /content/drive/MyDrive/\"Colab Notebooks\"/kaggle_api/kaggle.json ~/.kaggle\n",
    "  !pip install kaggle transformers\n",
    "  !chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "  !kaggle datasets download keimoriyama/train-dataset-coleridge\n",
    "  !unzip train-dataset-coleridge.zip\n",
    "  BIO_LABEL = \"only_bio_labeled_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoQ82tlUbN-p",
    "outputId": "2d1fdacd-4612-46ab-ca45-baeda2b45edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bio_labeled_dataset.csv       sample_data\n",
      "drive\t\t\t      train-dataset-coleridge.zip\n",
      "only_bio_labeled_dataset.csv  train_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NcTXnGKMchIw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "EcwVErh6dHBx",
    "outputId": "ae26cba3-2d37-422a-b9d0-2da224e39ed9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>BIO_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it includes a crosswalk between isced and the ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common core of data ccd survey</td>\n",
       "      <td>B I I I O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6 three longitudinal studies have been conduct...</td>\n",
       "      <td>O O O O O O O O O O B O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the data were collected on a north american br...</td>\n",
       "      <td>O O O O O O B I I I I I O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>noaa c cap land coverage http www csc noaa gov...</td>\n",
       "      <td>B I I O O O O O O O O O O O O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence                                          BIO_label\n",
       "0  it includes a crosswalk between isced and the ...  O O O O O O O O O O O O O O O O O O O O O O O ...\n",
       "1                     common core of data ccd survey                                        B I I I O O\n",
       "2  6 three longitudinal studies have been conduct...  O O O O O O O O O O B O O O O O O O O O O O O ...\n",
       "3  the data were collected on a north american br...                O O O O O O B I I I I I O O O O O O\n",
       "4  noaa c cap land coverage http www csc noaa gov...                      B I I O O O O O O O O O O O O"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(BIO_LABEL)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7u18IHOadThs"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, SequentialSampler, RandomSampler\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "from transformers import BertTokenizer, BertConfig, BertForTokenClassification\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "tag_to_idx = { \"B\":1, \"I\": 2,\"O\": 3, \"X\": 4, \"[CLS]\": 5, \"[SEP]\": 6, \"[PAD]\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Y2S1zl6-qgSe"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "EJzBz-4ldyEZ"
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(len(df)):\n",
    "    strings = df.iloc[i]\n",
    "    sentence = strings['sentence']\n",
    "    label = strings[\"BIO_label\"]\n",
    "    if sentence is np.nan:\n",
    "        continue\n",
    "    #sentence = sentence.split()\n",
    "    #label = label.split()\n",
    "    train_data.append((sentence, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "a2a0ea9cb723408db59e6f2d058f5229",
      "10f9ac90d6244f6787fe3976517d610b",
      "c33c87a01c89438397fbface03240879",
      "dc4a7aed467d420ab86587cfa765b07c",
      "eaa354a1cc384f4d856c3855ba02135e",
      "72488cde130a4664a38fa7daef476414",
      "7ef1bfa83e2e4bf5be7aa6801bde2ea6",
      "28143f90fce541a6b35a777d31718ab1"
     ]
    },
    "id": "veDivMQwqwnZ",
    "outputId": "7ba4ab08-e90d-4d35-b092-38b432fdc3f1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a0ea9cb723408db59e6f2d058f5229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=55285.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentences,labels = [], []\n",
    "for data in tqdm(zip(train_data), total = len(train_data)):\n",
    "  sentence = data[0][0]\n",
    "  label = data[0][1]\n",
    "  expanded_label, words = [], []\n",
    "  tokenized = tokenizer.tokenize(sentence)\n",
    "  # tokenized.insert(0, '[CLS]')\n",
    "  # tokenized.append('[SEP]')\n",
    "  label = label.split()\n",
    "  label.insert(0, '[CLS]')\n",
    "  # label.append('[SEP]')\n",
    "  label_idx = 0\n",
    "  for i, subwords in enumerate(tokenized):\n",
    "    if \"#\" in subwords:\n",
    "      words.append(subwords)\n",
    "      expanded_label.append(\"X\")\n",
    "      # print(i, subwords, label[label_idx], label_idx)\n",
    "      if (i+1) < len(tokenized) and \"#\" not in tokenized[i+1]:\n",
    "        label_idx+=1\n",
    "    else:\n",
    "      # print(i, subwords, label[label_idx], label_idx)\n",
    "      words.append(subwords)\n",
    "      expanded_label.append(label[label_idx])\n",
    "      if (i+1) < len(tokenized) and\"#\" not in tokenized[i+1]:\n",
    "        label_idx+=1\n",
    "  expanded_label.append(\"[SEP]\")\n",
    "  tokenized_sentences.append(words)\n",
    "  labels.append(expanded_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-d2_cavQ9AK",
    "outputId": "a9d89005-2b87-4336-af2c-2133bf6200ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'includes',\n",
       " 'a',\n",
       " 'cross',\n",
       " '##walk',\n",
       " 'between',\n",
       " 'is',\n",
       " '##ced',\n",
       " 'and',\n",
       " 'the',\n",
       " '1990',\n",
       " 'classification',\n",
       " 'of',\n",
       " 'instruction',\n",
       " '##al',\n",
       " 'programs',\n",
       " 'c',\n",
       " '##ip',\n",
       " 'the',\n",
       " 'official',\n",
       " 'u',\n",
       " 's',\n",
       " 'education',\n",
       " 'program',\n",
       " 'classification',\n",
       " 'system',\n",
       " 'and',\n",
       " 'cross',\n",
       " '##walk',\n",
       " '##s',\n",
       " 'between',\n",
       " 'is',\n",
       " '##ced',\n",
       " 'and',\n",
       " 'the',\n",
       " 'educational',\n",
       " 'level',\n",
       " 'classification',\n",
       " '##s',\n",
       " 'used',\n",
       " 'in',\n",
       " 'the',\n",
       " 'principal',\n",
       " 'u',\n",
       " 's',\n",
       " 'national',\n",
       " 'education',\n",
       " 'databases',\n",
       " 'the',\n",
       " 'integrated',\n",
       " 'posts',\n",
       " '##ec',\n",
       " '##onda',\n",
       " '##ry',\n",
       " 'education',\n",
       " 'data',\n",
       " 'system',\n",
       " 'i',\n",
       " '##ped',\n",
       " '##s',\n",
       " 'which',\n",
       " 'collects',\n",
       " 'posts',\n",
       " '##ec',\n",
       " '##onda',\n",
       " '##ry',\n",
       " 'data',\n",
       " 'and',\n",
       " 'the',\n",
       " 'common',\n",
       " 'core',\n",
       " 'of',\n",
       " 'data',\n",
       " 'survey',\n",
       " 'cc',\n",
       " '##d',\n",
       " 'which',\n",
       " 'collects',\n",
       " 'data',\n",
       " 'on',\n",
       " 'primary',\n",
       " 'and',\n",
       " 'secondary',\n",
       " 'education']"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIB3391Bzr19",
    "outputId": "7128672f-11b2-4beb-b0b1-cb38cc44e480"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "config = BertConfig.from_pretrained(model_name, num_labels = len(tag_to_idx))\n",
    "model = BertForTokenClassification.from_pretrained(model_name, config=config)\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr = 5e-5)\n",
    "#scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda= lambda epoch: 0.95**epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "9pA0zAe9ixYr"
   },
   "outputs": [],
   "source": [
    "class BERT_ner(nn.Module):\n",
    "\n",
    "  def __init__(self, model, num_tags):\n",
    "    super(BERT_ner, self).__init__()\n",
    "    self.model = model\n",
    "    self.start_trainsitions = nn.Parameter(torch.empty(num_tags))\n",
    "    self.end_transitinos = nn.Parameter(torch.empty(num_tags))\n",
    "    self.transitions = nn.Parameter(torch.empty(num_tags, num_tags))\n",
    "  \n",
    "  def reset_params(self):\n",
    "    nn.init.uniform(self.start_trainsitions, -0.1,0.1)\n",
    "    nn.init.uniform(self.end_trainsitions, -0.1,0.1)\n",
    "    nn.init.uniform(self.trainsitions, -0.1,0.1)\n",
    "\n",
    "  def forward(self, sentnece, masks, labels):\n",
    "    output = model(sentence, masks, labels = labels)\n",
    "    # print(output)\n",
    "    logits = output.logits\n",
    "    print(logits.size())\n",
    "    score = self._conpute_score(logits, tags, masks)\n",
    "    return {\"loss\": output.loss, \"logits\": logits}\n",
    "\n",
    "  def _compute_score(self, output, tags, masks):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "j1KCCMXBmGXt"
   },
   "outputs": [],
   "source": [
    "max_len = 256\n",
    "\n",
    "class sentence_datasets(Dataset):\n",
    "  def __init__(self, sentences, labels, tokenizer, bio2idx, max_len):\n",
    "    self.sentences = sentences\n",
    "    self.labels = labels\n",
    "    self.bio2idx = bio2idx\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    sentence = self.sentences[index]\n",
    "    label = self.labels[index]\n",
    "    inputs = tokenizer.encode_plus(sentence, None, \n",
    "                                   is_split_into_words=True,\n",
    "                                   max_length = self.max_len,\n",
    "                                   pad_to_max_length = True)\n",
    "    ids = inputs['input_ids']\n",
    "    label = [self.bio2idx[x] for x in label]\n",
    "    mask = inputs['attention_mask']\n",
    "    label.extend([0]*256)\n",
    "    label = label[:self.max_len]\n",
    "    ids = torch.tensor(ids, dtype = torch.long)\n",
    "    label = torch.tensor(label, dtype = torch.long)\n",
    "    mask = torch.tensor(mask, dtype = torch.long)\n",
    "    return {'ids':ids, 'mask':mask, 'tags': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "BnXVU-rHnobf"
   },
   "outputs": [],
   "source": [
    "dataset = sentence_datasets(tokenized_sentences, labels, tokenizer, tag_to_idx, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBO6bQk-HaIc",
    "outputId": "1ae123e3-d4ee-4964-ad7f-98b2fb1aaa3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([  101,  1122,  2075,   170,  2771,   108,   108,  2647,  1206,  1110,\n",
       "           108,   108,   172,  1174,  1105,  1103,  1997,  5393,  1104,  8235,\n",
       "           108,   108,  2393,  2648,   172,   108,   108,   178,  1643,  1103,\n",
       "          2078,   190,   188,  1972,  1788,  5393,  1449,  1105,  2771,   108,\n",
       "           108,  2647,   108,   108,   188,  1206,  1110,   108,   108,   172,\n",
       "          1174,  1105,  1103,  4339,  1634,  5393,   108,   108,   188,  1215,\n",
       "          1107,  1103,  3981,   190,   188,  1569,  1972, 19908,  1103,  6576,\n",
       "          8345,   108,   108,   174,  1665,   108,   108,  1113,  1810,   108,\n",
       "           108,   187,  1183,  1972,  2233,  1449,   178,   108,   108,   185,\n",
       "          1174,   108,   108,   188,  1134, 19213,  8345,   108,   108,   174,\n",
       "          1665,   108,   108,  1113,  1810,   108,   108,   187,  1183,  2233,\n",
       "          1105,  1103,  1887,  4160,  1104,  2233,  5980, 14402,   108,   108,\n",
       "           173,  1134, 19213,  2233,  1113,  2425,  1105,  3718,  1972,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]),\n",
       " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'tags': tensor([5, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 4, 4, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 1, 2,\n",
       "         2, 2, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "KOPrAMEplZjf"
   },
   "outputs": [],
   "source": [
    "ner_model = BERT_ner(model, len(tag_to_idx)).to(device)\n",
    "\n",
    "train_index, test_index = train_test_split(range(int(len(dataset))), test_size = 0.3)\n",
    "batch_size = 32\n",
    "train_dataset = Subset(dataset, train_index)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "test_dataset = Subset(dataset, test_index)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "064c3c372d0c4a4dbff1b3db190e86fe",
      "0068d2dd2de7433eac32874ae1049eb4",
      "56ad1cbe1085404a997ba134086449f1",
      "565c3fa926d840f8a07596ea3aaf7d35",
      "c3cfdc6a33cd4e218e8c4899012987d2",
      "6545a280b9c74f829aa7146f86d425ca",
      "6e31c70f6bd1425b92ab2841be21abaf",
      "1da0a535ab3c4649bb59489383b30fca"
     ]
    },
    "id": "r7RLslhLgiVd",
    "outputId": "f4a9ead6-ab04-436e-ed71-d2f870b52e38"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064c3c372d0c4a4dbff1b3db190e86fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "total_train_loss, total_test_loss = [], []\n",
    "epochs = 5\n",
    "for _ in tqdm(range(epochs)):\n",
    "  train_loss, test_loss = [], []\n",
    "  \n",
    "  model.train()\n",
    "  for data in train_dataloader:\n",
    "    # print(sentence, tags)\n",
    "    model.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "    # sentence = tokenizer(sentence, is_split_into_words=True, padding=True)['input_ids']\n",
    "    sentence = data['ids'].to(device)\n",
    "    tags = data['tags'].to(device)\n",
    "    masks = data['mask'].to(device)\n",
    "    # print(sentence.size(), tags.size())\n",
    "    output = ner_model(sentence, masks, labels = tags)\n",
    "    loss = output['loss']\n",
    "    # print(loss.size())\n",
    "    train_loss.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "  total_train_loss.append(sum(train_loss)/len(train_loss))\n",
    "\n",
    "  model.eval()\n",
    "  for data in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "      sentence = data['ids'].to(device)\n",
    "      tags = data['tags'].to(device)\n",
    "      masks = data['mask'].to(device)\n",
    "      loss = ner_model(sentence, masks, labels = tags)['loss']\n",
    "      test_loss.append(loss.item())\n",
    "  total_test_loss.append(sum(test_loss)/len(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMwP3SeFzJSI"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/Coleridge Initiative/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B48Bu2uEF4ce",
    "outputId": "1af9dfe6-fd50-45ab-deaf-06d080b2f761"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Coleridge Initiative/model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woQkdbWcJoZp"
   },
   "outputs": [],
   "source": [
    "d = df.iloc[1]\n",
    "sentence = d['sentence']\n",
    "label = d['BIO_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Q2Dhjm4KL87",
    "outputId": "a576b004-7da3-473c-b058-1ca951a4c8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1887,  4160,  1104,  2233, 14402,  1181,  5980,   102]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = tokenizer.encode(sentence)\n",
    "input = torch.tensor(input, dtype = torch.long)\n",
    "input = input.unsqueeze(0).to(device)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70nynIeyGvBM"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwogX-DfIf0s"
   },
   "outputs": [],
   "source": [
    "idx_to_tag = {v: k for k, v in tag_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83BYuLr-I2DH"
   },
   "outputs": [],
   "source": [
    "ans = torch.argmax(output['logits'], dim = 2)\n",
    "predict = [idx_to_tag[x.item()] for x in ans.squeeze(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cqdQxLSRKlnn",
    "outputId": "26d28329-ae56-413d-ea77-758f0439f17d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'B', 'I', 'I', 'I', 'O', '[PAD]', '[SEP]', '[PAD]']"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 65648/65648 [00:00<00:00, 596539.39it/s]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "epoch:1\n",
      "train_loss:nan    val_loss:nan\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NER_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0068d2dd2de7433eac32874ae1049eb4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "064c3c372d0c4a4dbff1b3db190e86fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_56ad1cbe1085404a997ba134086449f1",
       "IPY_MODEL_565c3fa926d840f8a07596ea3aaf7d35"
      ],
      "layout": "IPY_MODEL_0068d2dd2de7433eac32874ae1049eb4"
     }
    },
    "10f9ac90d6244f6787fe3976517d610b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1da0a535ab3c4649bb59489383b30fca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28143f90fce541a6b35a777d31718ab1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "565c3fa926d840f8a07596ea3aaf7d35": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1da0a535ab3c4649bb59489383b30fca",
      "placeholder": "​",
      "style": "IPY_MODEL_6e31c70f6bd1425b92ab2841be21abaf",
      "value": " 0/5 [00:00&lt;?, ?it/s]"
     }
    },
    "56ad1cbe1085404a997ba134086449f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6545a280b9c74f829aa7146f86d425ca",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c3cfdc6a33cd4e218e8c4899012987d2",
      "value": 0
     }
    },
    "6545a280b9c74f829aa7146f86d425ca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e31c70f6bd1425b92ab2841be21abaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72488cde130a4664a38fa7daef476414": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ef1bfa83e2e4bf5be7aa6801bde2ea6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2a0ea9cb723408db59e6f2d058f5229": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c33c87a01c89438397fbface03240879",
       "IPY_MODEL_dc4a7aed467d420ab86587cfa765b07c"
      ],
      "layout": "IPY_MODEL_10f9ac90d6244f6787fe3976517d610b"
     }
    },
    "c33c87a01c89438397fbface03240879": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72488cde130a4664a38fa7daef476414",
      "max": 55285,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eaa354a1cc384f4d856c3855ba02135e",
      "value": 55285
     }
    },
    "c3cfdc6a33cd4e218e8c4899012987d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dc4a7aed467d420ab86587cfa765b07c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28143f90fce541a6b35a777d31718ab1",
      "placeholder": "​",
      "style": "IPY_MODEL_7ef1bfa83e2e4bf5be7aa6801bde2ea6",
      "value": " 55285/55285 [00:42&lt;00:00, 1286.49it/s]"
     }
    },
    "eaa354a1cc384f4d856c3855ba02135e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
